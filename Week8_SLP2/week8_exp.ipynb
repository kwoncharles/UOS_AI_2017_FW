{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadData train-images.idx3-ubyte\n",
      "magicNumber 2051\n",
      "nData 60000\n",
      "nRow 28\n",
      "nCol 28\n",
      "done.\n",
      "\n",
      "loadLabel train-labels.idx1-ubyte\n",
      "magicNumber 2049\n",
      "nData 60000\n",
      "done.\n",
      "\n",
      "loadData t10k-images.idx3-ubyte\n",
      "magicNumber 2051\n",
      "nData 10000\n",
      "nRow 28\n",
      "nCol 28\n",
      "done.\n",
      "\n",
      "loadLabel t10k-labels.idx1-ubyte\n",
      "magicNumber 2049\n",
      "nData 10000\n",
      "done.\n",
      "\n",
      "len(trDataList) 60000\n",
      "len(trLabelList) 60000\n",
      "len(tsDataList) 10000\n",
      "len(tsLabelList) 10000\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import struct as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as nr\n",
    "import pickle as pkl\n",
    "\n",
    "'''\n",
    "# MNIST 데이터 경로\n",
    "_SRC_PATH = u'..\\\\'\n",
    "_TRAIN_DATA_FILE = _SRC_PATH + u'\\\\train-images.idx3-ubyte'\n",
    "_TRAIN_LABEL_FILE = _SRC_PATH + u'\\\\train-labels.idx1-ubyte'\n",
    "_TEST_DATA_FILE = _SRC_PATH + u'\\\\t10k-images.idx3-ubyte'\n",
    "_TEST_LABEL_FILE = _SRC_PATH + u'\\\\t10k-labels.idx1-ubyte'\n",
    "'''\n",
    "_TRAIN_DATA_FILE = 'train-images.idx3-ubyte'\n",
    "_TRAIN_LABEL_FILE = 'train-labels.idx1-ubyte'\n",
    "_TEST_DATA_FILE = 't10k-images.idx3-ubyte'\n",
    "_TEST_LABEL_FILE = 't10k-labels.idx1-ubyte'\n",
    "\n",
    "\n",
    "# MNIST 데이터 크기 (28x28)\n",
    "_N_ROW = 28                 # 세로 28픽셀\n",
    "_N_COL = 28                 # 가로 28픽셀\n",
    "_N_PIXEL = _N_ROW * _N_COL\n",
    "\n",
    "# 출력 이미지 경로\n",
    "_DST_PATH = u'img_gray'\n",
    "\n",
    "\n",
    "\n",
    "def drawImage(dataArr, fn):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(dataArr, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.savefig(fn)\n",
    "    \n",
    "    \n",
    "    \n",
    "def loadData(fn):\n",
    "    print 'loadData', fn\n",
    "    \n",
    "    fd = open(fn, 'rb')\n",
    "    \n",
    "    # header: 32bit integer (big-endian)\n",
    "    magicNumber = st.unpack('>I', fd.read(4))[0]\n",
    "    nData = st.unpack('>I', fd.read(4))[0]\n",
    "    nRow = st.unpack('>I', fd.read(4))[0]\n",
    "    nCol = st.unpack('>I', fd.read(4))[0]\n",
    "    \n",
    "    print 'magicNumber', magicNumber\n",
    "    print 'nData', nData\n",
    "    print 'nRow', nRow\n",
    "    print 'nCol', nCol\n",
    "    \n",
    "    # data: unsigned byte\n",
    "    dataList = []\n",
    "    for i in range(nData):\n",
    "        dataRawList = fd.read(_N_PIXEL)\n",
    "        dataNumList = st.unpack('B' * _N_PIXEL, dataRawList)\n",
    "        #dataArr = np.array(dataNumList).reshape(_N_ROW, _N_COL)\n",
    "        dataArr = np.array(dataNumList)\n",
    "        # overflow 수정\n",
    "        dataList.append(dataArr.astype('float32')/255.0)\n",
    "        \n",
    "    fd.close()\n",
    "    \n",
    "    print 'done.'\n",
    "    print\n",
    "    \n",
    "    return dataList\n",
    "    \n",
    "\n",
    "\n",
    "def loadLabel(fn):\n",
    "    print 'loadLabel', fn\n",
    "    \n",
    "    fd = open(fn, 'rb')\n",
    "    \n",
    "    # header: 32bit integer (big-endian)\n",
    "    magicNumber = st.unpack('>I', fd.read(4))[0]\n",
    "    nData = st.unpack('>I', fd.read(4))[0]\n",
    "    \n",
    "    print 'magicNumber', magicNumber\n",
    "    print 'nData', nData\n",
    "    \n",
    "    # data: unsigned byte\n",
    "    labelList = []\n",
    "    for i in range(nData):\n",
    "        dataLabel = st.unpack('B', fd.read(1))[0]\n",
    "        labelList.append(dataLabel)\n",
    "        \n",
    "    fd.close()\n",
    "    \n",
    "    print 'done.'\n",
    "    print\n",
    "    \n",
    "    return labelList\n",
    "\n",
    "\n",
    "\n",
    "def loadMNIST():\n",
    "    # 학습 데이터 / 레이블 로드\n",
    "    trDataList = loadData(_TRAIN_DATA_FILE)\n",
    "    trLabelList = loadLabel(_TRAIN_LABEL_FILE)\n",
    "    \n",
    "    # 테스트 데이터 / 레이블 로드\n",
    "    tsDataList = loadData(_TEST_DATA_FILE)\n",
    "    tsLabelList = loadLabel(_TEST_LABEL_FILE)\n",
    "    \n",
    "    return trDataList, trLabelList, tsDataList, tsLabelList\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trDataList, trLabelList, tsDataList, tsLabelList = loadMNIST()\n",
    "    \n",
    "    print 'len(trDataList)', len(trDataList)\n",
    "    print 'len(trLabelList)', len(trLabelList)\n",
    "    print 'len(tsDataList)', len(tsDataList)\n",
    "    print 'len(tsLabelList)', len(tsLabelList)\n",
    "    \n",
    "    if op.exists(_DST_PATH) == False:\n",
    "        os.mkdir(_DST_PATH)\n",
    "''' \n",
    "    # 샘플로 5개씩만 출력해보기\n",
    "    for i in range(5):\n",
    "        label = trLabelList[i]\n",
    "        dstFn = _DST_PATH + u'\\\\tr_%d_label_%d.png' % (i, label)\n",
    "        #print '%d-th train data: label=%d' % (i, label)\n",
    "        drawImage(trDataList[i], dstFn)\n",
    "        \n",
    "        dstFn = _DST_PATH + u'\\\\tr_%d_label_%d.txt' % (i, label)\n",
    "        np.savetxt(dstFn, trDataList[i], fmt='%4d')\n",
    "        \n",
    "    for i in range(5):\n",
    "        label = tsLabelList[i]\n",
    "        dstFn = _DST_PATH + u'\\\\ts_%d_label_%d.png' % (i, label)\n",
    "        #print '%d-th test data: label=%d' % (i, label)\n",
    "        drawImage(tsDataList[i], dstFn)\n",
    "        \n",
    "        dstFn = _DST_PATH + u'\\\\ts_%d_label_%d.txt' % (i, label)\n",
    "        np.savetxt(dstFn, tsDataList[i], fmt='%4d')\n",
    "        \n",
    "'''\n",
    "\n",
    "# weight를 pkl파일로 저장하는 method\n",
    "def save(fn, obj):\n",
    "    fd = open(fn,'wb')\n",
    "    pkl.dump(obj,fd)\n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "reshape 왜 했었지?\n",
    "\n",
    "np.array(trDataList).astype(np.float32)\n",
    "#for i in range(len(trDataList)):\n",
    "#    trDataList[i]=trDataList[i].reshape(1,784)\n",
    "np.array(trLabelList)\n",
    "np.array(tsDataList).astype(np.float32)\n",
    "#for i in range(len(tsDataList)):\n",
    "#    tsDataList[i]=tsDataList[i].reshape(1,784)\n",
    "np.array(tsLabelList)\n",
    "'''\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training, Test Data reshape\n",
    "\n",
    "for i in range(len(trDataList)):\n",
    "    trDataList[i]=trDataList[i].reshape(1,784)\n",
    "for i in range(len(tsDataList)):\n",
    "    tsDataList[i]=tsDataList[i].reshape(1,784)\n",
    "    \n",
    "# Training, Test Label reshape as Onehot\n",
    "\n",
    "trlabel_onehot=np.zeros([len(trLabelList),10])\n",
    "\n",
    "for i in range(0,len(trLabelList)):\n",
    "    trlabel_onehot[i][trLabelList[i]] = 1\n",
    "    \n",
    "tslabel_onehot=np.zeros([len(tsLabelList),10])\n",
    "\n",
    "for i in range(0,len(tsLabelList)):\n",
    "    tslabel_onehot[i][tsLabelList[i]] = 1\n",
    "    \n",
    "\n",
    "# Data사용이 용이하게 numpy array로 바꿔준다\n",
    "    \n",
    "trDataList = np.array(trDataList)\n",
    "tsDataList = np.array(tsDataList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Single layer perceptron\n",
    "class SLP:\n",
    "    # class선언 시 learning rate를 인자로 받는다\n",
    "    def __init__(self,lr):\n",
    "        self.lr = lr\n",
    "        self.weight = nr.rand(784,10)\n",
    "        # Batch size, Training epoch 횟수 설정\n",
    "        self.batch_size = 10000\n",
    "        self.tr_epochs = 10\n",
    "        \n",
    "    def activation(self,x):\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    \n",
    "    def train(self,feat,label):\n",
    "        \n",
    "        total_batch = len(feat)/self.batch_size\n",
    "        \n",
    "        # 분류 결과가 가장 좋은 파라미터를 저장하기 위해 변수 선언\n",
    "        self.best_weight=self.weight\n",
    "        self.best_error=100.0\n",
    "        fp = open(\"train_log.txt\",'wt')\n",
    "        \n",
    "        print \"Learning starts!\"\n",
    "        for epoch in range(self.tr_epochs):\n",
    "            \n",
    "            # 매 학습마다 데이터를 섞어주기 위해 Index변수 따로 선언\n",
    "            trainIdx = range(0,len(feat))\n",
    "            nr.shuffle(trainIdx)\n",
    "            \n",
    "            fp.write(\"--------- epoch{} ---------\\n\".format(epoch+1))\n",
    "            print \"--------- epoch{} ---------\".format(epoch+1)\n",
    "            for i in range(total_batch):\n",
    "                cost = 0\n",
    "                \n",
    "                for j in range(i*self.batch_size,(i+1)*self.batch_size):\n",
    "                    # 갱신할 weight를 임시로 저장할 변수 선언\n",
    "                    new_weight=self.weight\n",
    "                    \n",
    "                    # 활성화함수 통과\n",
    "                    result=self.activation(np.dot(feat[trainIdx[j]]/10,self.weight))\n",
    "                    \n",
    "                    # weight 갱신 (column별로 갱신)\n",
    "                    for k in range(10):\n",
    "                        # weight 갱신을 위해 reshape을 해준다\n",
    "                        new_weight[:,[k]] = new_weight[:,[k]] + (self.lr*(label[trainIdx[j]][k]-result[0][k])\\\n",
    "                                    *result[0][k]*(1-result[0][k])*feat[trainIdx[j]]).reshape(784,1)\n",
    "                \n",
    "                    # 평균 cost 계산\n",
    "                    cost += (np.sum(label[trainIdx[j]]-result)**2)/2\n",
    "                    \n",
    "                    self.weight=new_weight\n",
    "                    \n",
    "                # 평균 cost 계산\n",
    "                cost = cost/self.batch_size\n",
    "                fp.write(\"{}. cost: {}\\n\".format(j+1,np.sum(cost)))\n",
    "                print \"{}. cost: {}\".format(j+1,np.sum(cost))\n",
    "                \n",
    "                error=self.predict(feat,label,self.weight)\n",
    "                fp.write(\"Error_rate: {}\\n\".format(error))\n",
    "                print(\"Error_rate: {}\".format(error))\n",
    "                \n",
    "                # 분류 결과가 지금까지 중 가장 좋았다면 결과와 weight을 저장\n",
    "                if(error<self.best_error):\n",
    "                    self.best_error=error\n",
    "                    self.best_weight=self.weight\n",
    "                    \n",
    "                # learning rate decay\n",
    "                self.lr = self.lr*0.99\n",
    "        print \"Learning ends!\"\n",
    "                    \n",
    "        \n",
    "    def predict(self,feat,label,weight):\n",
    "        fp = open(\"test_output.txt\",'wt')\n",
    "        correct=0\n",
    "        \n",
    "        # 데이터를 순서대로 돌며 예측값과 정답을 비교\n",
    "        for i in range(len(feat)):\n",
    "            pred=np.argmax(np.dot(feat[i],weight))\n",
    "            if(label[i][pred]==1.0):\n",
    "                correct+=1\n",
    "        avg=np.float32(correct)/len(feat)\n",
    "        fp.write(\"Error rate of Test data : {}\".format(1.0-avg))\n",
    "        return (1.0-avg)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning starts!\n",
      "--------- epoch1 ---------\n",
      "10000. cost: 3.18575125136\n",
      "Error_rate: 0.166016666667\n",
      "20000. cost: 0.149973331686\n",
      "Error_rate: 0.1412\n",
      "30000. cost: 0.107347947109\n",
      "Error_rate: 0.131383333333\n",
      "40000. cost: 0.0976718754438\n",
      "Error_rate: 0.12765\n",
      "50000. cost: 0.0884530221552\n",
      "Error_rate: 0.12275\n",
      "60000. cost: 0.0833055929786\n",
      "Error_rate: 0.11865\n",
      "--------- epoch2 ---------\n",
      "10000. cost: 0.0783019639648\n",
      "Error_rate: 0.115616666667\n",
      "20000. cost: 0.0738320641086\n",
      "Error_rate: 0.1148\n",
      "30000. cost: 0.0717106312096\n",
      "Error_rate: 0.113083333333\n",
      "40000. cost: 0.0706254443391\n",
      "Error_rate: 0.1117\n",
      "50000. cost: 0.0683848871235\n",
      "Error_rate: 0.111516666667\n",
      "60000. cost: 0.0680173096468\n",
      "Error_rate: 0.10995\n",
      "--------- epoch3 ---------\n",
      "10000. cost: 0.0669510609916\n",
      "Error_rate: 0.109116666667\n",
      "20000. cost: 0.0645151828591\n",
      "Error_rate: 0.107633333333\n",
      "30000. cost: 0.0660950929113\n",
      "Error_rate: 0.106816666667\n",
      "40000. cost: 0.0621015585124\n",
      "Error_rate: 0.107733333333\n",
      "50000. cost: 0.0625798132735\n",
      "Error_rate: 0.10635\n",
      "60000. cost: 0.0615812546456\n",
      "Error_rate: 0.1054\n",
      "--------- epoch4 ---------\n",
      "10000. cost: 0.0614016515011\n",
      "Error_rate: 0.105716666667\n",
      "20000. cost: 0.0594544383014\n",
      "Error_rate: 0.104566666667\n",
      "30000. cost: 0.0614158064402\n",
      "Error_rate: 0.103333333333\n",
      "40000. cost: 0.059934326281\n",
      "Error_rate: 0.103466666667\n",
      "50000. cost: 0.0621711372734\n",
      "Error_rate: 0.10405\n",
      "60000. cost: 0.058646643309\n",
      "Error_rate: 0.102366666667\n",
      "--------- epoch5 ---------\n",
      "10000. cost: 0.0591632189537\n",
      "Error_rate: 0.102183333333\n",
      "20000. cost: 0.0589140132201\n",
      "Error_rate: 0.102016666667\n",
      "30000. cost: 0.057399259845\n",
      "Error_rate: 0.101566666667\n",
      "40000. cost: 0.057498185234\n",
      "Error_rate: 0.101916666667\n",
      "50000. cost: 0.0590806016732\n",
      "Error_rate: 0.101233333333\n",
      "60000. cost: 0.0574478633815\n",
      "Error_rate: 0.100733333333\n",
      "--------- epoch6 ---------\n",
      "10000. cost: 0.057513417043\n",
      "Error_rate: 0.100666666667\n",
      "20000. cost: 0.0586428919036\n",
      "Error_rate: 0.100266666667\n",
      "30000. cost: 0.0559744621566\n",
      "Error_rate: 0.1005\n",
      "40000. cost: 0.0557139731857\n",
      "Error_rate: 0.100216666667\n",
      "50000. cost: 0.0572749611266\n",
      "Error_rate: 0.10005\n",
      "60000. cost: 0.0557100588606\n",
      "Error_rate: 0.0992666666667\n",
      "--------- epoch7 ---------\n",
      "10000. cost: 0.0565615938885\n",
      "Error_rate: 0.0994333333333\n",
      "20000. cost: 0.0571840867241\n",
      "Error_rate: 0.0993666666667\n",
      "30000. cost: 0.056381762993\n",
      "Error_rate: 0.0989\n",
      "40000. cost: 0.0543264722557\n",
      "Error_rate: 0.0988833333333\n",
      "50000. cost: 0.055023080608\n",
      "Error_rate: 0.0989\n",
      "60000. cost: 0.0554112044093\n",
      "Error_rate: 0.0982666666667\n",
      "--------- epoch8 ---------\n",
      "10000. cost: 0.0549257277262\n",
      "Error_rate: 0.0979166666667\n",
      "20000. cost: 0.0563067457938\n",
      "Error_rate: 0.09795\n",
      "30000. cost: 0.0543073856865\n",
      "Error_rate: 0.09765\n",
      "40000. cost: 0.0554167664481\n",
      "Error_rate: 0.0973333333333\n",
      "50000. cost: 0.0559092466845\n",
      "Error_rate: 0.0979\n",
      "60000. cost: 0.0529023249025\n",
      "Error_rate: 0.0973833333333\n",
      "--------- epoch9 ---------\n",
      "10000. cost: 0.0530367445498\n",
      "Error_rate: 0.0967166666667\n",
      "20000. cost: 0.0547484442447\n",
      "Error_rate: 0.0970166666667\n",
      "30000. cost: 0.0550229079371\n",
      "Error_rate: 0.0979\n",
      "40000. cost: 0.055019679138\n",
      "Error_rate: 0.0966166666667\n",
      "50000. cost: 0.05394658553\n",
      "Error_rate: 0.0966833333333\n",
      "60000. cost: 0.0545264078053\n",
      "Error_rate: 0.0971333333333\n",
      "--------- epoch10 ---------\n",
      "10000. cost: 0.0536421558521\n",
      "Error_rate: 0.0969166666667\n",
      "20000. cost: 0.0564847183516\n",
      "Error_rate: 0.09605\n",
      "30000. cost: 0.0520903860882\n",
      "Error_rate: 0.09555\n",
      "40000. cost: 0.053516733614\n",
      "Error_rate: 0.0950166666667\n",
      "50000. cost: 0.0553561923154\n",
      "Error_rate: 0.0959166666667\n",
      "60000. cost: 0.0523087666621\n",
      "Error_rate: 0.0963833333333\n",
      "Learning ends!\n"
     ]
    }
   ],
   "source": [
    "test = SLP(0.05)\n",
    "test.train(trDataList,trlabel_onehot)\n",
    "\n",
    "# 학습 결과가 가장 좋은 weight pkl파일로 저장\n",
    "param = test.best_weight\n",
    "save('best_param.pkl',param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74270000000000003"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.predict(val_data,val_label,test.best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
